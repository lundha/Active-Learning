{
    "args": {
    "CIFAR10": {
    "load_data_args": {
        "data_dir": "../datasets/cifar10/",
        "num_classes": 10,
        "file_ending": ".png",
        "num_channels": 3
        },
        "learning_args": {
            
        }
    }, 
    "MNIST": {
    "load_data_args": {
        "data_dir": "../datasets/mnist/",
        "num_classes": 10,
        "file_endin": ".png",
        "num_channels": 1
        },
        "learning_args": {

        }
    },
    "PLANKTON10": {
        "load_data_args": {
        "data_dir": "../datasets/train10",
        "img_dim": 32, 
        "num_classes": 10,
        "file_ending": ".jpg",
        "num_channels": 3
        },
        "learning_args": {

        }
    },
    "AILARON_PLANKTON": {
        "load_data_args": {
        'data_dir': "../datasets/ailaron_plankton",
        'img_dim': 32, 
        'num_classes': 6,
        'file_ending': ".tiff",
        'num_channels': 3,
        },
        "learning_args": {

        }
    }
}

learning_args = {'MNIST': 
{
    'data_set': 'MNIST',
    'n_epoch': 30,
    'img_dim': 28,
    'num_classes': 10,  
    'transform': transforms.Compose(
                    [transforms.Grayscale(num_output_channels=3),
                    transforms.RandomHorizontalFlip(),
                    transforms.RandomVerticalFlip(),
                    transforms.RandomAffine(degrees=7,translate=(0.1,0.1),fillcolor=255),
                    transforms.RandomCrop(size=32,padding=4),
                    transforms.ToTensor(), 
                    transforms.Normalize(mean=(0.95,), std=(0.2,))]), 
    'tr_args': {'batch_size': 64, 'lr': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'num_workers': NUM_WORKERS},
    'valid_args': {'batch_size': 400, 'num_workers': NUM_WORKERS},
    'te_args': {'batch_size': 1000, 'lr': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'num_workers': NUM_WORKERS},
},
'CIFAR10': 
{
    'data_set': 'CIFAR10',
    'n_epoch': 30,
    'img_dim': 32,
    'num_classes': 10,  
    'transform': transforms.Compose(
                    [transforms.RandomHorizontalFlip(),
                    transforms.RandomVerticalFlip(),
                    transforms.RandomAffine(degrees=7,translate=(0.1,0.1),fillcolor=255),
                    transforms.RandomCrop(size=32,padding=4),
                    transforms.ToTensor(), 
                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))]), 
    'tr_args': {'batch_size': 64, 'lr': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'num_workers': NUM_WORKERS},
    'valid_args': {'batch_size': 400, 'num_workers': NUM_WORKERS},
    'te_args': {'batch_size': 1000, 'lr': 0.0001, 'weight_decay': 0.0001, 'momentum': 0.9, 'num_workers': NUM_WORKERS},
},
'PLANKTON10':
{
    'data_set': 'PLANKTON10',
    'n_epoch': 30,
    'img_dim': 32,
    'num_classes': 10,
    'transform': transforms.Compose(
                    [transforms.Grayscale(num_output_channels=3),
                    transforms.RandomHorizontalFlip(),
                    transforms.RandomVerticalFlip(),
                    transforms.RandomAffine(degrees=7,translate=(0.1,0.1),fillcolor=255),
                    transforms.Resize((32,32)),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=(0.95,), std=(0.2,))]), 
    'tr_args': {'batch_size': 32, 'lr': 0.004, 'weight_decay': 0.0001, 'num_workers': NUM_WORKERS},
    'valid_args': {'batch_size': 379, 'num_workers': NUM_WORKERS},
    'te_args': {'batch_size': 1000, 'lr': 0.004, 'weight_decay': 0.0001, 'num_workers': NUM_WORKERS},         
},
'AILARON_PLANKTON':
{
    'data_set': 'AILARON_PLANKTON',
    'n_epoch': 30,
    'img_dim': 32,
    'num_classes': 6,
    'transform': transforms.Compose(
                    [transforms.Grayscale(num_output_channels=3),
                    transforms.RandomHorizontalFlip(),
                    transforms.RandomVerticalFlip(),
                    transforms.RandomAffine(degrees=7,translate=(0.1,0.1),fillcolor=255),
                    transforms.Resize((32,32)),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=(0.95,), std=(0.2,))]), 
    'tr_args': {'batch_size': 32, 'lr': 0.004, 'weight_decay': 0.0001, 'num_workers': NUM_WORKERS},
    'valid_args': {'batch_size': 379, 'num_workers': NUM_WORKERS},
    'te_args': {'batch_size': 1000, 'lr': 0.004, 'weight_decay': 0.0001, 'num_workers': NUM_WORKERS},  
}
}
